===============================================================================
                           GPU共享技术使用说明
===============================================================================

目录:
1. GPU共享技术概述
2. 主流GPU共享技术对比
3. NVIDIA MPS (Multi-Process Service)
4. NVIDIA vGPU (Virtual GPU)
5. Docker GPU共享
6. Kubernetes GPU共享
7. 性能优化建议
8. 故障排除指南
9. 安全注意事项
10. 常见问题解答

===============================================================================
1. GPU共享技术概述
===============================================================================

GPU共享技术允许多个进程或虚拟机同时使用单个物理GPU资源，主要目的是：
- 提高GPU资源利用率
- 降低硬件成本
- 支持多租户场景
- 实现资源弹性分配

主要应用场景：
- 深度学习训练/推理
- 科学计算
- 图形渲染
- 虚拟桌面基础架构(VDI)

===============================================================================
2. 主流GPU共享技术对比
===============================================================================

技术类型        | 优点                      | 缺点                    | 适用场景
----------------|-------------------------|------------------------|----------
NVIDIA MPS     | 低延迟，高性能            | 仅支持同型号GPU        | 单机多进程
NVIDIA vGPU    | 完全隔离，支持虚拟机      | 需要特定硬件支持        | 虚拟化环境
Docker GPU     | 轻量级，易于部署          | 隔离性较弱             | 容器化应用
K8s GPU        | 支持集群管理              | 配置复杂               | 大规模部署

===============================================================================
3. NVIDIA MPS (Multi-Process Service)
===============================================================================

3.1 工作原理
MPS通过创建一个客户端-服务器架构，允许多个进程共享GPU上下文，
减少上下文切换开销，提高并发性能。

3.2 安装配置
# 安装NVIDIA驱动和CUDA
sudo apt-get install nvidia-driver-xxx
sudo apt-get install cuda-toolkit-xxx

# 启用MPS服务
sudo nvidia-smi -i 0 -c EXCLUSIVE_PROCESS
nvidia-cuda-mps-control -d

# 设置MPS控制
echo 'set_default_thread_per_threadblock_limit 1024' | nvidia-cuda-mps-control

3.3 使用示例
# Python代码中使用MPS
import os
os.environ['CUDA_MPS_PIPE_DIRECTORY'] = '/tmp/nvidia-mps'
os.environ['CUDA_MPS_ACTIVE_THREAD_PERCENTAGE'] = '50'

===============================================================================
4. NVIDIA vGPU (Virtual GPU)
===============================================================================

4.1 系统要求
- 支持vGPU的NVIDIA GPU
- VMware vSphere/ESXi或KVM
- NVIDIA vGPU软件授权

4.2 配置步骤
# 安装vGPU Manager
sudo ./NVIDIA-vGPU-x.x.x-linux.run

# 配置vGPU实例
mdevctl types
mdevctl define -u <uuid> -t <type> -p <pci>

# 在虚拟机中配置
<devices>
  <hostdev mode='subsystem' type='mdev' managed='no'>
    <source>
      <address uuid='<uuid>'/>
    </source>
  </hostdev>
</devices>

===============================================================================
5. Docker GPU共享
===============================================================================

5.1 安装nvidia-docker
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

5.2 使用示例
# 运行GPU容器
docker run --gpus all -it nvidia/cuda:11.0-base

# 指定GPU数量
docker run --gpus 2 -it nvidia/cuda:11.0-base

# 指定特定GPU
docker run --gpus '"device=0,1"' -it nvidia/cuda:11.0-base

===============================================================================
6. Kubernetes GPU共享
===============================================================================

6.1 安装NVIDIA设备插件
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.9.0/nvidia-device-plugin.yml

6.2 GPU共享配置
# 使用time-slicing实现GPU共享
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-sharing-config
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        renameByDefault: false
        failRequestsGreaterThanOne: true
        resources:
        - name: nvidia.com/gpu
          replicas: 10

6.3 Pod配置示例
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:11.0-base
    resources:
      limits:
        nvidia.com/gpu: 1

===============================================================================
7. 性能优化建议
===============================================================================

7.1 资源分配策略
- 根据实际需求合理分配GPU资源
- 使用GPU监控工具动态调整分配
- 避免过度分配导致的性能下降

7.2 内存管理
- 合理设置GPU内存限制
- 使用内存池技术减少分配开销
- 定期清理未使用的GPU内存

7.3 调度优化
- 使用亲和性规则优化GPU任务分配
- 实现智能调度避免资源争抢
- 考虑使用GPU拓扑优化通信

===============================================================================
8. 故障排除指南
===============================================================================

8.1 常见问题及解决方案

问题1: MPS服务启动失败
解决步骤:
1. 检查GPU驱动版本兼容性
2. 确认GPU未被其他进程占用
3. 检查系统权限设置

问题2: vGPU实例创建失败
解决步骤:
1. 验证GPU是否支持vGPU
2. 检查vGPU Manager状态
3. 确认配置文件格式正确

问题3: Docker容器无法访问GPU
解决步骤:
1. 确认nvidia-docker正确安装
2. 检查容器运行时配置
3. 验证GPU设备权限

8.2 日志查看
# MPS日志
cat /tmp/nvidia-mps/log

# Docker日志
docker logs <container_id>

# Kubernetes日志
kubectl logs <pod_name>

===============================================================================
9. 安全注意事项
===============================================================================

9.1 访问控制
- 实施严格的用户权限管理
- 使用GPU隔离技术防止数据泄露
- 定期更新GPU驱动和相关软件

9.2 资源保护
- 设置合理的资源限制
- 实施配额管理
- 监控异常资源使用

9.3 数据安全
- 加密GPU内存中的敏感数据
- 安全清理GPU缓存
- 实施审计日志记录

===============================================================================
10. 常见问题解答
===============================================================================

Q1: 如何监控GPU使用情况？
A: 使用nvidia-smi命令或NVIDIA DCGM工具
   nvidia-smi -l 1  # 每秒刷新一次

Q2: 如何处理GPU内存不足？
A: 1. 减小batch size
   2. 使用梯度累积
   3. 实施模型并行
   4. 使用混合精度训练

Q3: 如何优化多GPU通信？
A: 1. 使用NCCL进行高效通信
   2. 优化网络拓扑
   3. 合理设置通信组大小

Q4: 如何处理GPU热迁移？
A: 1. 确保vGPU支持热迁移
   2. 配置共享存储
   3. 实施检查点机制

===============================================================================
免责声明：
本说明仅供参考，实际使用时请根据具体环境和需求进行调整。
使用GPU共享技术时，请确保遵守相关软件许可协议。

版本：1.0
